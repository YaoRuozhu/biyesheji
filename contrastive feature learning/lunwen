以自动驾驶的图像识别子系统中的神经网络为例，为度量神经网络能承受多大的噪声干扰，一种方法是讨论在一定输入空间范围内，神经网络输出的区域是否可靠。例如，在图5.3.2中的神经网络的两个输入单元x_1与x_2的输入范围均是[-1,1]区间时，验证其输出的值域范围是否还在可以接受的区域范围内，例如，x_11∈[1,4]。这里可以将两个输入单元的输入理解成为输入图像的两个关键像素点值，例如，交通停止标志的关键像素；而输出则可理解为分类的结果，例如，x_11∈[1,4]的区间是分类为交通停止标志的区间，而其他区间则是未知的分类区间。在此基础上，度量神经网络最大可承受干扰的程度其实就是寻找最大的x_1与x_2的输入范围使得x_11∈[1,4]仍然能得到满足。这类方法属于形式化验证，因为其涉及到对于神经网络输入输出之间关系的形式化分析且以验证为主要形式。一般地，形式化验证方法将神经网络作为白盒来进行分析，通过逐层分解输入输出关系找到原始输入与最终输出的关系，从而判定原始输入范围是否会产生不可接受的输出，继而确定神经网络的鲁棒性边界（不会导致结果变化的输入范围）。
为实现神经网络鲁棒性的度量，现有的一种较为有效的技术方案是形式化验证技术中的符号传播(Symbolic Propagation)技术及其相关变种。以图5.3.2中这个简单的神经网络验证过程为例，符号传播从神经网络的输入层开始为每一层上的每一个神经元描写其与上一层的神经元之间的关系；在经过激活函数时，神经元间的关系变得复杂，为防止关系数量的膨胀以及减小验证误差，需要利用一定的方式对神经元间的关系做约束（如图5.3.3，以图5.3.2中x_3与x_5的关系为例：x_5=max⁡〖(0,x_3)〗，即ReLU激活函数，得知x_3的上下界u_3与l_3后可计算得到x_5的上下界：l_5≤x_5≤u_5⟹0≤x_5≤u_3/(u_3-l_3 )(x_3-l_3)；这样的上下界近似分析保证了任意x取值范围的讨论总是由上界与下界两个线性边界来给定，不会由于非线性激活函数的引入而变得复杂；这里要注意l_3≤0）；直到神经网络最后的输出层，符号传播可以得到两两层之间的相互关系，而对于输出层而言则可以用变量替换法得到其与输入层之间的关系，从而再利用输入层已知的变量取值范围求解得到输出的取值范围。这样就能明确对于输入层的干扰是否会使得输出层产生错误的输出，从而验证神经网络是否鲁棒。对一次干扰的验证可以采用上述的方式进行，而在通过多次迭代验证后，可以一定程度上确认神经网络能接受的最大干扰值，即可实现神经网络鲁棒性的度量。
通过上面所述的形式化验证方法，在给定输入区间的情况下，我们可以验证神经网络的输出是否仍然正确。那么，在具体的图像识别场景下，通过给定图像以及图像所受噪声干扰的上下限可以求得图像的像素取值区间，进而可以利用上述方法验证特定神经网络是否能够抵抗给定的噪声干扰。如图5.3.4所示，对于一张原图像以及给定的噪声幅度可以求得该图像的值域上下限，通过形式化验证可以求得神经网络对这张图像的输入上下限区间的输出区间范围，若该范围的输出均是准确一致的，则可以说明该神经网络在这张图像上可以抵抗所给噪声幅度的干扰。在图5.3.4中，输出区间大于等于0.5即可说明，对于给定的输入区间，神经网络的输出均为正确输出Tinca。
上述方法最大问题在于其所度量出的鲁棒性值不可以在结构不同的神经网络之间相互比较，仅是在结构相同的神经网络之间该鲁棒性值才有一定借鉴意义。这是因为符号传播类的方法或其变种为了提升验证效率，会对神经网络中的激活函数做一定的估计处理。例如，在图5.3.3中会对ReLU函数做上下界的近似处理。该处理的目的主要是为了确保每一个经过激活函数的神经元的输出只有上下界需要讨论，从而避免了需要通过分类讨论来明确上下界使得需要讨论的情况逐层指数增加的情形。具体地，当ReLU函数作为激活函数时，如果不采用图5.3.3中的方式做上下界估计，而直接采用ReLU函数计算上下界，则需要讨论当输入在小于等于0与当输入在大于0两种不同情况下的上下界。虽然后者不需要做估计，但是每经过一个激活函数的神经元都要做这样的分类讨论，整个验证问题复杂度将呈指数上升。而正是这种简化问题的激活函数估计方法，使得1）神经网络的鲁棒性估计变得极为不准确，尤其是在深层次或者神经元数量大的网络中，过度的估计使得计算出的鲁棒性极其不可靠；2）不同结构的神经网络被估计的程度不同，也就导致了估计出的鲁棒性不是立足于相同估计程度，也就不能进行比较。上述两点共同使得符号传播等一大类基于估计的神经网络鲁棒性度量的方法均不能用于商业产品。
另一大类神经网络鲁棒性度量的方法是经验主义测试，也就是基于相同的测试数据集对给定的一个或多个神经网络进行鲁棒性评分。该技术方案相对简单，在构造测试数据集后可直接统计神经网络的准确性作为鲁棒性分数。该方法的核心在于构造尽可能完整全面的测试数据集来模拟神经网络可能受到的不同程度且不同类型的干扰。ImageNet-C和ImageNet-P是两个针对ImageNet图像数据集构造的干扰数据集。数据集包含的干扰包括了对图像数据的光线变化、大小缩放、旋转切割、雨雪雾天气变化等几大类。
图5.3.5展示的是ImageNet-C数据集中所包含的部分数据干扰类型，包含不同程度的随机噪声，图像模糊化处理、图像前景干扰、图像亮度对比度与色调变化，以及像素化处理等。值得说明的是，针对每一张图片，不同类型的干扰会以不同的程度作用于该图片，从而生成多张受相同干扰的图像。通过衡量神经网络在这些干扰图片的判断上所表现出的准确度，我们可以一定程度上度量神经网络的鲁棒性。目前，多数的学术文献也是以类似的方式进行对神经网络抵抗对抗样本攻击能力的度量。该方法的主要优势是简单高效，能够快速地给出一个粗略的神经网络可靠性度量结果。图5.3.6展示的是ImageNet-P数据集所包含的三种图像干扰的示例，从左到右依次是：切割，倾斜和雨点效果。同样，该数据集也用于直接测试神经网络面向所含三类干扰的鲁棒性。
单纯地利用经验主义测试来进行神经网络鲁棒性度量的缺点在于对于该度量结果精度不足，并且没有理论保障。经验性的测试结果的准确性极大程度上依赖于验证数据的完整性与准确性，不充分的测试无法提供有统计意义的度量结果。通过经验构造出的数据集在神经网络可靠性度量方面无法给出理论上的保证，例如，确保某神经网络针对某张图片的识别在一定的旋转干扰下必然不会发生错误。没有数学上的形式化证明使得经验性测试的结果只作为参考结果用来度量神经网络鲁棒性。另外，目前神经网络经验性测试的结果通常不会给出神经网络鲁棒性的置信度，对特定干扰的抵抗能力的具体估计不足。例如，图像识别神经网络对于抵抗图像旋转的能力并没有采用神经网络能抵抗多少图像旋转角度的形式给出，仅仅通过对干扰数据集的测试准确性的度量来侧面反映神经网络鲁棒性，可解释性等方面有所欠缺。
