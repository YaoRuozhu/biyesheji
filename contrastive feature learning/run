import dataset
import simclr
import torch.nn as nn    #神经网络API
import torch.optim as optim
from argparse import Namespace
import matplotlib.pyplot as plt
import torch.utils.data as Data
import fgsm
import torch

batch_size = 2
learning_rate = 3e-3
epoches = 5
hparams = Namespace(
    lr=0.000630957344480193,
    epochs=10,
    batch_size=batch_size,
    train_size=1000,
    validation_size=200
)


# 载入训练集与测试集数据
train_data = dataset.train_mini_train()
#train_ds = simclr.PretrainingDatasetWrapper(train_data, debug=False)
train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
test_data = dataset.test_mini_test()
#test_ds = simclr.PretrainingDatasetWrapper(test_data, debug=False)
test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)

# 载入网络结构
model = simclr.ImageEmbedding()
attackModel=torch.load("./model-0.pt")

def forward(self, X):
    return self.model(X)

# 声明损失函数及优化器
loss_fn = simclr.ContrastiveLoss(hparams.batch_size)
optim = optim.Adam(params=model.parameters(), lr=learning_rate)

# 输出网络结构信息
# printNetInfo(net)

train_accs = []
test_accs = []
losses = []
loss_attack = nn.CrossEntropyLoss()
for epoch in range(epoches):
    model.train()  # 训练
    for step, data in enumerate(train_loader, start=0):
        images, labels = data
        #新的batch达不到预设的数量要求
        if images.size(0)!=train_loader.batch_size:
            continue
        X = images
        #需要计算全部节点的梯度
        X.requires_grad_()
        #backward的过程计算梯度
        loss_attack(attackModel(X),labels.long()).backward()
        #X的梯度
        data_grad = X.grad
        #下面的backwards不计算梯度
        X.requires_grad=False
        Y = fgsm.fgsm_attack(X, 0.1, data_grad)
        optim.zero_grad()  # 优化器梯度清0
        embX, projectionX = model(X)
        embY, projectionY = model(Y)
        loss = loss_fn(projectionX, projectionY)  # 计算损失函数
        loss.backward()  # 反向传播求梯度
        optim.step()  # 优化器进一步优化

        rate = (step + 1) / len(train_loader)
        a = "*" * int(rate * 50)
        b = "." * int((1 - rate) * 50)
        print("\repoch:%s train loss:%3.0f%%:%.4f" % (epoch, int(rate * 100), loss), end="  ")
    losses.append(loss)

    model.eval()  # 测试
    model.aux_logits = False
    train_acc = dataset.TestAccuracy(model, train_loader)
    train_accs.append(train_acc)

    test_acc = dataset.TestAccuracy(model, test_loader)
    test_accs.append(test_acc)

    print("train_acc:", train_acc, " test_acc:", test_acc)

    # 模型训练损失可视化
    #data.plot_loss_result(losses)
    #plt.show()

    # 训练集与测试集精度可视化
    dataset.plot_train_and_test_result(train_accs, test_accs)
    plt.show()
