import torch.nn as nn


class SimpleNet1(nn.Module):
    '''定义神经网络结构'''

    def __init__(self):
        super(SimpleNet, self).__init__()
        self.conv1 = nn.Sequential(  # (1, 8, 8)
            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=2, stride=1, padding=1),  # (4, 8, 8)
        )
        self.conv2 = nn.Sequential(
            nn.ReLU(),  # (4, 8, 8)
        )
        self.conv3 = nn.Sequential(
            nn.MaxPool2d(kernel_size=2)  # (4,4,4) 不改变通道数
        )
        self.conv4 = nn.Sequential(
            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=2, stride=1, padding=1),  # (8,5,5)
        )
        self.conv5 = nn.Sequential(
            nn.ReLU(),  # (8,5,5)
        )
        self.conv6 = nn.Sequential(
            nn.MaxPool2d(kernel_size=2)  # (8,2,2)
        )
        self.fc = nn.Linear(8 * 2 * 2, 10)  # (10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.conv6(x)

        x = x.view(x.size(0), -1)  # 相当于Flatten
        x = self.fc(x)
        return x


networkNodes = [100, 50, 20]


class SimpleNet(nn.Module):
    def __init__(self, inputSize):
        super(SimpleNet, self).__init__()
        self.layers = nn.ModuleList()
        networkNodes.insert(0, inputSize)
        for i in range(len(networkNodes) - 1):
            self.layers.append(nn.Linear(networkNodes[i], networkNodes[i + 1]))
            if (i != (len(networkNodes) - 2)):
                self.fc = nn.ReLU()
                self.layers.append(self.fc)
        # self.model=nn.Sequential(
        #     nn.Linear(inputSize,networkNodes[0]),
        #     nn.Linear(networkNodes[0],networkNodes[1]),
        #     nn.Linear(inputSize,networkNodes[1],networkNodes[2]),
        #     nn.Linear(inputSize,networkNodes[2],networkNodes[3])
        # )

    def PrintNetwork(self):
        for layer in self.layers:
            print(layer)

    def forward(self, data):
        data = data.view(data.size(0), -1)
        for layer in self.layers:
            data = layer(data)
        return data
