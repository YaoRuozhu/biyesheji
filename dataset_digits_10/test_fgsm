import matplotlib.pyplot as plt
import time
from matplotlib.colors import ListedColormap
from keras import backend as K
import data
import robustness_calculator
import draw_robustness
import os
import numpy as np
import keras
from keras.datasets import mnist
from keras.utils import np_utils
from keras.models import Sequential
from keras.models import load_model
from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten
from keras.optimizers import Adam
import os


os.environ["TF_CPP_MIN_LOG_LEVEL"]='1' # 这是默认的显示等级，显示所有信息
os.environ["TF_CPP_MIN_LOG_LEVEL"]='2' # 只显示 warning 和 Error
os.environ["TF_CPP_MIN_LOG_LEVEL"]='3'

#os.environ["CUDA_VISIBLE_DEVICES"] = "1"

#gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)

#sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))


count_correct_close_list = []
count_wrong_list = []
rand_list = []
model_robustness_list = []
iter_no_list = []
test_accuracy_list = []
model_orig_robustness_list = []
time_total = 0
time_orig_total = 0


radius = data.radius
count_feature = data.count_feature
count_data = data.count_data
count_label = 10
count_train = int(0.8*count_data)
count_test = int(0.2*count_data)

data_attack = np.empty((0, count_feature+1))
data_orig = data.data_orig
data_fgsm1 = np.load('data_fgsm'+str(0.01)+'.npy')
data_fgsm2 = np.load('data_fgsm'+str(0.02)+'.npy')
data_fgsm3 = np.load('data_fgsm'+str(0.03)+'.npy')
data_fgsm4 = np.load('data_fgsm'+str(0.04)+'.npy')
data_fgsm5 = np.load('data_fgsm'+str(0.05)+'.npy')
data_fgsm6 = np.load('data_fgsm'+str(0.06)+'.npy')
data_fgsm7 = np.load('data_fgsm'+str(0.07)+'.npy')
data_fgsm8 = np.load('data_fgsm'+str(0.08)+'.npy')
data_fgsm9 = np.load('data_fgsm'+str(0.09)+'.npy')
data_attack = np.vstack((data_fgsm1, data_fgsm2, data_fgsm3, data_fgsm4, data_fgsm5, data_fgsm6, data_fgsm7, data_fgsm8, data_fgsm9))
x_train_orig = data_orig[:count_train, 0:count_feature]
x_train = x_train_orig
x_test = data_orig[-count_test:, 0:count_feature]
y_train_orig = data_orig[:count_train, count_feature]
y_train = y_train_orig
y_test_orig = data_orig[-count_test:, count_feature]
y_test = keras.utils.to_categorical(y_test_orig, num_classes=count_label)
#data_train_orig = np.hstack((x_train_orig, y_train_orig.reshape(count_train, 1), np.arange(1, count_train+1, 1).reshape(count_train, 1), data.radius*np.ones((count_train, 1)), 10*np.ones((count_train, 1))))
data_train_orig = data_orig[0: count_train, :]
y_orig = keras.utils.to_categorical(y_train_orig, num_classes=count_label)
count_column = data_train_orig[0, :].size

model = Sequential()
model.add(Conv2D(input_shape=(8, 8, 1), kernel_size=(5, 5), filters=20, activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))
model.add(Conv2D(kernel_size=(5, 5), filters=50, activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))
model.add(Flatten())
model.add(Dense(500, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])


model_orig = Sequential()
model_orig.add(Conv2D(input_shape=(8, 8, 1), kernel_size=(5, 5), filters=20, activation='relu'))
model_orig.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))
model_orig.add(Conv2D(kernel_size=(5, 5), filters=50, activation='relu', padding='same'))
model_orig.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))
model_orig.add(Flatten())
model_orig.add(Dense(500, activation='relu'))
model_orig.add(Dense(10, activation='softmax'))
model_orig.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

model.load_weights('my_model_weights.h5')
model_orig.load_weights('my_model_weights.h5')

for iter_no in range(10):

    time_start = time.time()

    x_attack = data_attack[:, 0:count_feature]
    y_attack = data_attack[:, count_feature]

    x_train = np.vstack([x_train_orig, x_attack])
    y_train = np.append(y_train_orig, y_attack)


    np.random.seed(iter_no+100)
    np.random.shuffle(x_train)
    np.random.seed(iter_no + 100)
    np.random.shuffle(y_train)

    y_train = keras.utils.to_categorical(y_train, num_classes=count_label)
    x_train = x_train.reshape(-1, 8, 8, 1)
    x_test = x_test.reshape(-1, 8, 8, 1)
    model.fit(x_train, y_train, epochs=4, batch_size=16, validation_data=(x_test, y_test))
    time_end = time.time()
    time1 = time_end - time_start
    time_total = time_total + time1
    pred_test = model.predict(x_train_orig.reshape(-1, 8, 8, 1))
    pred_test = np.argmax(pred_test, axis=1).reshape(count_train, 1)
    correct_test = np.equal(y_train_orig.reshape(count_train, 1), pred_test) + 0
    test_accuracy = correct_test.sum().astype(np.int32) / count_train

    print('accu' + str(test_accuracy))

    iter_no_list.append(iter_no)
    print(str(iter_no) + 'time:' + str(time_total))
    print(iter_no)

    model_robustness = robustness_calculator.robustness_calculator(model, data_orig)
    print(str(iter_no) + 'model:' + str(model_robustness))
    model_robustness_list.append(model_robustness)

figure = draw_robustness.draw_robustness_accuracy(iter_no_list, model_orig_robustness_list, model_robustness_list)
plt.savefig('robustness')
